# generated by datamodel-codegen:
#   filename:  aiApplication.json
#   timestamp: 2026-02-01T09:44:00+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, ConfigDict, Field
from typing_extensions import Annotated

from . import ability


class VoteType(Enum):
    votedUp = 'votedUp'
    votedDown = 'votedDown'
    unVoted = 'unVoted'


class AccessDetails(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    timestamp: Annotated[
        ability.Timestamp,
        Field(
            description='Timestamp of data asset accessed for creation, update, read.'
        ),
    ]
    accessedBy: Annotated[
        Optional[ability.EntityReference],
        Field(
            None,
            description='User, Pipeline, Query that created,updated or accessed the data asset',
        ),
    ]
    accessedByAProcess: Annotated[
        Optional[str],
        Field(
            None,
            description='Any process that accessed the data asset that is not captured in OpenMetadata.',
        ),
    ]


class ApplicationType(Enum):
    Chatbot = 'Chatbot'
    Agent = 'Agent'
    Copilot = 'Copilot'
    Assistant = 'Assistant'
    RAG = 'RAG'
    CodeGenerator = 'CodeGenerator'
    DataAnalyst = 'DataAnalyst'
    AutomationBot = 'AutomationBot'
    MultiAgent = 'MultiAgent'
    Custom = 'Custom'


class DevelopmentStage(Enum):
    Proposal = 'Proposal'
    Development = 'Development'
    Testing = 'Testing'
    Staging = 'Staging'
    Production = 'Production'
    Deprecated = 'Deprecated'
    Unauthorized = 'Unauthorized'


class Purpose(Enum):
    Primary = 'Primary'
    Reasoning = 'Reasoning'
    Embedding = 'Embedding'
    CodeGeneration = 'CodeGeneration'
    Fallback = 'Fallback'
    CostOptimization = 'CostOptimization'


class SelectionCriteria(BaseModel):
    queryTypes: Annotated[
        Optional[List[str]],
        Field(None, description='Types of queries this model handles'),
    ]
    maxTokens: Annotated[
        Optional[int],
        Field(
            None, description='Use this model only if query is under this token count'
        ),
    ]
    costThreshold: Annotated[
        Optional[float],
        Field(
            None, description='Use this model if cost per query is under this threshold'
        ),
    ]


class Parameters(BaseModel):
    temperature: Optional[float] = None
    maxTokens: Optional[int] = None
    topP: Optional[float] = None
    frequencyPenalty: Optional[float] = None
    presencePenalty: Optional[float] = None


class ModelConfiguration(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    model: Annotated[
        ability.EntityReference, Field(description='Reference to LLMModel entity')
    ]
    purpose: Annotated[
        Purpose, Field(description='Purpose of this model in the application workflow')
    ]
    selectionCriteria: Annotated[
        Optional[SelectionCriteria],
        Field(None, description='Criteria for when to use this model'),
    ]
    parameters: Annotated[
        Optional[Parameters],
        Field(None, description='Model-specific parameters for this application'),
    ]


class RegistrationStatus(Enum):
    Registered = 'Registered'
    Unregistered = 'Unregistered'
    PendingApproval = 'PendingApproval'
    Approved = 'Approved'
    Rejected = 'Rejected'


class RiskLevel(Enum):
    Low = 'Low'
    Medium = 'Medium'
    High = 'High'
    Critical = 'Critical'


class RiskAssessment(BaseModel):
    riskLevel: Optional[RiskLevel] = None
    riskFactors: Annotated[
        Optional[List[str]], Field(None, description='Identified risk factors')
    ]
    mitigations: Annotated[
        Optional[List[str]],
        Field(None, description='Risk mitigation measures in place'),
    ]
    assessedBy: Optional[str] = None
    assessedAt: Optional[ability.Timestamp] = None


class DataClassification(BaseModel):
    accessesPII: Annotated[
        Optional[bool],
        Field(
            None,
            description='Does this application access Personally Identifiable Information',
        ),
    ]
    accessesSensitiveData: Annotated[
        Optional[bool],
        Field(None, description='Does this application access sensitive business data'),
    ]
    dataCategories: Annotated[
        Optional[List[str]], Field(None, description='Categories of data accessed')
    ]
    dataRetentionPeriod: Annotated[
        Optional[str],
        Field(None, description='Data retention period for application logs'),
    ]


class ComplianceFramework(Enum):
    EU_AI_Act = 'EU_AI_Act'
    Singapore_Model_AI_Governance = 'Singapore_Model_AI_Governance'
    Canada_AIDA = 'Canada_AIDA'
    US_AI_Bill_of_Rights = 'US_AI_Bill_of_Rights'
    NIST_AI_RMF = 'NIST_AI_RMF'
    ISO_IEC_42001 = 'ISO_IEC_42001'
    UK_AI_Regulation = 'UK_AI_Regulation'
    China_AI_Regulations = 'China_AI_Regulations'
    Custom = 'Custom'


class RiskClassification(Enum):
    Minimal = 'Minimal'
    Limited = 'Limited'
    High = 'High'
    Unacceptable = 'Unacceptable'


class ProhibitedPractices(BaseModel):
    subliminalManipulativeTechniques: Annotated[
        Optional[bool],
        Field(
            None,
            description="Art 5(1)(a): Subliminal techniques beyond person's consciousness",
        ),
    ]
    exploitationOfVulnerabilities: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(b): Exploitation of vulnerabilities due to age, disability, or social/economic situation',
        ),
    ]
    socialScoringSystem: Annotated[
        Optional[bool],
        Field(None, description='Art 5(1)(c): Social scoring by public authorities'),
    ]
    riskAssessmentCriminalOffences: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(d): Risk assessment based solely on profiling for predicting criminal offences',
        ),
    ]
    facialRecognitionDatabaseCreation: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(e): Untargeted scraping of facial images for facial recognition databases',
        ),
    ]
    emotionInferenceWorkplaceEducation: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(f): Emotion recognition in workplace and education',
        ),
    ]
    biometricCategorisation: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(g): Biometric categorisation inferring sensitive attributes',
        ),
    ]
    realTimeBiometricIdentification: Annotated[
        Optional[bool],
        Field(
            None,
            description='Art 5(1)(h): Real-time remote biometric identification in public spaces by law enforcement',
        ),
    ]


class HighRiskSystems(BaseModel):
    criticalInfrastructure: Annotated[
        Optional[bool],
        Field(
            None,
            description='Annex III(1): Critical infrastructure (transport, water, gas, electricity, etc.)',
        ),
    ]
    educationVocationalTraining: Annotated[
        Optional[bool],
        Field(None, description='Annex III(3): Education and vocational training'),
    ]
    employment: Annotated[
        Optional[bool],
        Field(
            None,
            description='Annex III(4): Employment, workers management, and access to self-employment',
        ),
    ]
    essentialPrivateServices: Annotated[
        Optional[bool],
        Field(
            None,
            description='Annex III(5): Access to essential private services (credit, insurance, etc.)',
        ),
    ]
    essentialPublicServices: Annotated[
        Optional[bool], Field(None, description='Annex III(6): Law enforcement')
    ]
    lawEnforcement: Annotated[
        Optional[bool],
        Field(None, description='Annex III(6): Law enforcement purposes'),
    ]
    migrationAsylumBorderControl: Annotated[
        Optional[bool],
        Field(
            None,
            description='Annex III(7): Migration, asylum, and border control management',
        ),
    ]
    administrationOfJustice: Annotated[
        Optional[bool],
        Field(
            None,
            description='Annex III(8): Administration of justice and democratic processes',
        ),
    ]


class AssessmentType(Enum):
    Internal = 'Internal'
    ThirdParty = 'ThirdParty'
    NotRequired = 'NotRequired'


class ConformityAssessment(BaseModel):
    assessmentRequired: Annotated[
        Optional[bool],
        Field(None, description='Whether conformity assessment is required'),
    ]
    assessmentType: Annotated[
        Optional[AssessmentType],
        Field(None, description='Type of conformity assessment'),
    ]
    assessmentBody: Annotated[
        Optional[str],
        Field(None, description='Name of notified body performing assessment'),
    ]
    certificateNumber: Annotated[
        Optional[str], Field(None, description='Certificate number if issued')
    ]
    validUntil: Annotated[
        Optional[ability.Timestamp],
        Field(None, description='Certificate validity date'),
    ]


class TransparencyObligations(BaseModel):
    usersInformed: Annotated[
        Optional[bool],
        Field(None, description='Users are informed they are interacting with AI'),
    ]
    deepfakeLabeling: Annotated[
        Optional[bool],
        Field(None, description='AI-generated content is appropriately labeled'),
    ]
    emotionRecognitionDisclosure: Annotated[
        Optional[bool],
        Field(
            None,
            description='Emotion recognition or biometric categorization disclosed',
        ),
    ]


class EuAIActCompliance(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    riskClassification: Annotated[
        Optional[RiskClassification],
        Field(None, description='Risk classification under EU AI Act'),
    ]
    riskRationale: Annotated[
        Optional[str], Field(None, description='Rationale for the risk classification')
    ]
    prohibitedPractices: Annotated[
        Optional[ProhibitedPractices],
        Field(None, description='Article 5 prohibited AI practices assessment'),
    ]
    highRiskSystems: Annotated[
        Optional[HighRiskSystems],
        Field(None, description='Article 6 high-risk AI systems assessment'),
    ]
    conformityAssessment: Annotated[
        Optional[ConformityAssessment],
        Field(None, description='Conformity assessment status'),
    ]
    transparencyObligations: Annotated[
        Optional[TransparencyObligations],
        Field(None, description='Article 50 transparency obligations'),
    ]


class PrivacyLevel(Enum):
    Public = 'Public'
    Sensitive = 'Sensitive'
    PersonalData = 'PersonalData'


class FairnessRisk(Enum):
    Low = 'Low'
    Medium = 'Medium'
    High = 'High'


class BiasMitigationCoverage(Enum):
    None_ = 'None'
    Partial = 'Partial'
    Full = 'Full'


class ReliabilitySafetyRisk(Enum):
    Low = 'Low'
    Moderate = 'Moderate'
    High = 'High'


class TransparencyLevel(Enum):
    None_ = 'None'
    Partial = 'Partial'
    FullDisclosure = 'FullDisclosure'


class AccountabilityMeasures(BaseModel):
    hasOwner: Annotated[
        Optional[bool],
        Field(None, description='Has designated owner responsible for AI system'),
    ]
    subjectToHumanOversight: Annotated[
        Optional[bool],
        Field(None, description='Subject to human oversight and intervention'),
    ]
    auditTrailEnabled: Annotated[
        Optional[bool], Field(None, description='Comprehensive audit trail enabled')
    ]


class EnvironmentalConsciousness(Enum):
    LowRisk = 'LowRisk'
    MediumRisk = 'MediumRisk'
    HighRisk = 'HighRisk'


class EthicalAIAssessment(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    privacyLevel: Annotated[
        Optional[PrivacyLevel],
        Field(None, description='Level of privacy-sensitive data accessed'),
    ]
    fairnessRisk: Annotated[
        Optional[FairnessRisk],
        Field(None, description='Risk level for fairness and discrimination'),
    ]
    biasMitigationCoverage: Annotated[
        Optional[BiasMitigationCoverage],
        Field(None, description='Coverage of bias mitigation measures'),
    ]
    reliabilitySafetyRisk: Annotated[
        Optional[ReliabilitySafetyRisk],
        Field(None, description='Risk level for reliability and safety'),
    ]
    transparencyLevel: Annotated[
        Optional[TransparencyLevel],
        Field(None, description='Level of transparency in AI operations'),
    ]
    accountabilityMeasures: Annotated[
        Optional[AccountabilityMeasures],
        Field(None, description='Accountability measures in place'),
    ]
    environmentalConsciousness: Annotated[
        Optional[EnvironmentalConsciousness],
        Field(
            None,
            description='Environmental impact risk level (carbon footprint, energy consumption)',
        ),
    ]


class Status(Enum):
    Compliant = 'Compliant'
    PartiallyCompliant = 'PartiallyCompliant'
    NonCompliant = 'NonCompliant'
    UnderReview = 'UnderReview'
    NotApplicable = 'NotApplicable'


class Scope(Enum):
    Internal = 'Internal'
    External = 'External'
    Both = 'Both'


class ScopeAndDeployment(BaseModel):
    scope: Annotated[Optional[Scope], Field(None, description='Scope of AI usage')]
    deploymentRegions: Annotated[
        Optional[List[str]],
        Field(
            None,
            description='Geographic regions where deployed (relevant for jurisdiction)',
        ),
    ]
    affectedUserCount: Annotated[
        Optional[int], Field(None, description='Estimated number of affected users')
    ]


class Verification(BaseModel):
    isVerified: Annotated[
        Optional[bool], Field(None, description='Whether compliance has been verified')
    ]
    verifiedBy: Annotated[
        Optional[str],
        Field(None, description='Verifier (internal auditor, external body, etc.)'),
    ]
    verifiedAt: Annotated[
        Optional[ability.Timestamp],
        Field(None, description='Timestamp of verification'),
    ]
    verificationNotes: Annotated[
        Optional[str], Field(None, description='Notes from verification process')
    ]
    certificateUrl: Annotated[
        Optional[str],
        Field(None, description='URL to certificate or compliance documentation'),
    ]


class AiComplianceRecord(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    framework: ComplianceFramework
    assessedBy: Annotated[
        Optional[str],
        Field(None, description='Person or team who performed the assessment'),
    ]
    assessedAt: Annotated[
        Optional[ability.Timestamp],
        Field(None, description='When the assessment was performed'),
    ]
    nextReviewDate: Annotated[
        Optional[ability.Timestamp],
        Field(None, description='When the next compliance review is due'),
    ]
    status: Annotated[Status, Field(description='Compliance status')]
    euAIAct: Annotated[
        Optional[EuAIActCompliance],
        Field(
            None,
            description='EU AI Act specific assessment (only when framework is EU_AI_Act)',
        ),
    ]
    ethicalAssessment: Annotated[
        Optional[EthicalAIAssessment],
        Field(None, description='Ethical AI assessment applicable to most frameworks'),
    ]
    scopeAndDeployment: Annotated[
        Optional[ScopeAndDeployment],
        Field(None, description='Deployment scope relevant to compliance jurisdiction'),
    ]
    verification: Annotated[
        Optional[Verification],
        Field(None, description='Verification and certification status'),
    ]
    notes: Annotated[
        Optional[str],
        Field(
            None, description='Additional notes and findings from compliance assessment'
        ),
    ]
    remediationRequired: Annotated[
        Optional[List[str]],
        Field(None, description='List of remediation actions required for compliance'),
    ]


class DimensionScores(BaseModel):
    gender: Optional[float] = None
    race: Optional[float] = None
    age: Optional[float] = None
    religion: Optional[float] = None
    disability: Optional[float] = None
    socioeconomic: Optional[float] = None


class BiasMetrics(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    lastEvaluatedAt: Optional[ability.Timestamp] = None
    evaluationMethod: Annotated[
        Optional[str],
        Field(
            None,
            description='Method used for bias evaluation (e.g., Fairlearn, AI Fairness 360)',
        ),
    ]
    overallBiasScore: Annotated[
        Optional[float],
        Field(
            None,
            description='Overall bias score from 0-1, where higher values indicate more bias',
            ge=0.0,
            le=1.0,
        ),
    ]
    demographicParity: Annotated[
        Optional[float], Field(None, description='Demographic parity score')
    ]
    equalizedOdds: Annotated[
        Optional[float], Field(None, description='Equalized odds score')
    ]
    disparateImpact: Annotated[
        Optional[float], Field(None, description='Disparate impact ratio')
    ]
    dimensionScores: Annotated[
        Optional[DimensionScores],
        Field(None, description='Bias scores by demographic dimension'),
    ]
    testDataset: Annotated[
        Optional[ability.EntityReference],
        Field(None, description='Dataset used for bias evaluation'),
    ]
    biasDetected: Annotated[
        Optional[bool], Field(None, description='Whether significant bias was detected')
    ]
    remediationSteps: Annotated[
        Optional[List[str]],
        Field(None, description='Steps taken or recommended to remediate bias'),
    ]


class PerformanceMetrics(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    totalExecutions: Annotated[
        Optional[int], Field(None, description='Total number of executions')
    ]
    successRate: Annotated[
        Optional[float], Field(None, description='Success rate (0-1)')
    ]
    averageLatencyMs: Annotated[
        Optional[float], Field(None, description='Average latency in milliseconds')
    ]
    p95LatencyMs: Annotated[
        Optional[float],
        Field(None, description='95th percentile latency in milliseconds'),
    ]
    p99LatencyMs: Annotated[
        Optional[float],
        Field(None, description='99th percentile latency in milliseconds'),
    ]
    averageCost: Annotated[
        Optional[float], Field(None, description='Average cost per execution')
    ]
    totalCost: Annotated[
        Optional[float], Field(None, description='Total cost across all executions')
    ]
    currency: Optional[str] = 'USD'
    lastExecutionAt: Optional[ability.Timestamp] = None


class QualityMetrics(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    answerRelevancy: Annotated[
        Optional[float], Field(None, description='Answer relevancy score (0-1)')
    ]
    contextPrecision: Annotated[
        Optional[float], Field(None, description='Context precision score (0-1)')
    ]
    faithfulness: Annotated[
        Optional[float], Field(None, description='Faithfulness to source data (0-1)')
    ]
    hallucinationRate: Annotated[
        Optional[float], Field(None, description='Rate of hallucinations (0-1)')
    ]


class SafetyMetrics(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    piiLeakageRate: Annotated[
        Optional[float], Field(None, description='Rate of PII leakage incidents')
    ]
    harmfulContentRate: Annotated[
        Optional[float], Field(None, description='Rate of harmful content generated')
    ]
    promptInjectionAttempts: Annotated[
        Optional[int],
        Field(None, description='Number of prompt injection attempts detected'),
    ]
    blockedRequests: Annotated[
        Optional[int],
        Field(None, description='Number of requests blocked by safety filters'),
    ]


class Name(Enum):
    LangChain = 'LangChain'
    LlamaIndex = 'LlamaIndex'
    AutoGen = 'AutoGen'
    CrewAI = 'CrewAI'
    Semantic_Kernel = 'Semantic Kernel'
    Haystack = 'Haystack'
    Custom = 'Custom'


class Language(Enum):
    Python = 'Python'
    TypeScript = 'TypeScript'
    JavaScript = 'JavaScript'
    Java = 'Java'
    C_ = 'C#'
    Go = 'Go'


class FrameworkInfo(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    name: Optional[Name] = None
    version: Optional[str] = None
    language: Optional[Language] = None


class Votes(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    upVotes: Annotated[
        Optional[int], Field(0, description='Total up-votes the entity has')
    ]
    downVotes: Annotated[
        Optional[int], Field(0, description='Total down-votes the entity has')
    ]
    upVoters: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='List of all the Users who upVoted'),
    ]
    downVoters: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='List of all the Users who downVoted'),
    ]


class LifeCycle(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    created: Annotated[
        Optional[AccessDetails],
        Field(
            None, description='Access Details about created aspect of the data asset'
        ),
    ]
    updated: Annotated[
        Optional[AccessDetails],
        Field(
            None, description='Access Details about updated aspect of the data asset'
        ),
    ]
    accessed: Annotated[
        Optional[AccessDetails],
        Field(
            None, description='Access Details about accessed aspect of the data asset'
        ),
    ]


class AiCompliance(BaseModel):
    complianceRecords: Annotated[
        Optional[List[AiComplianceRecord]],
        Field(
            None, description='List of compliance assessments for different frameworks'
        ),
    ]


class GovernanceMetadata(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    registrationStatus: Annotated[
        Optional[RegistrationStatus],
        Field(None, description='Registration status - used to track Shadow AI'),
    ]
    registeredBy: Optional[str] = None
    registeredAt: Optional[ability.Timestamp] = None
    approvedBy: Optional[str] = None
    approvedAt: Optional[ability.Timestamp] = None
    riskAssessment: Annotated[
        Optional[RiskAssessment],
        Field(None, description='Risk assessment for this AI application'),
    ]
    dataClassification: Annotated[
        Optional[DataClassification],
        Field(None, description='Classification of data accessed by this application'),
    ]
    governancePolicies: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Governance policies applied to this application'),
    ]
    aiCompliance: Annotated[
        Optional[AiCompliance],
        Field(
            None,
            description='AI compliance assessments for various regulatory frameworks (EU AI Act, NIST AI RMF, etc.)',
        ),
    ]
    intakeNotes: Annotated[
        Optional[str],
        Field(
            None, description='Notes from AI governance intake form or review process'
        ),
    ]
    approvalComments: Annotated[
        Optional[str],
        Field(
            None,
            description='Comments from governance council on approval/rejection decision',
        ),
    ]


class AssetCertification(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    tagLabel: ability.TagLabel
    appliedDate: Annotated[
        ability.Timestamp,
        Field(description='The date when the certification was applied.'),
    ]
    expiryDate: Annotated[
        ability.Timestamp, Field(description='The date when the certification expires.')
    ]


class AIApplication(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    id: Annotated[
        ability.Uuid, Field(description='Unique identifier of the AI Application.')
    ]
    name: Annotated[
        ability.EntityName,
        Field(description='Name that identifies this AI Application.'),
    ]
    fullyQualifiedName: Annotated[
        Optional[ability.FullyQualifiedEntityName],
        Field(None, description='Fully qualified name of the AI Application.'),
    ]
    displayName: Annotated[
        Optional[str], Field(None, description='Display name for the AI Application.')
    ]
    description: Annotated[
        Optional[ability.Markdown],
        Field(
            None,
            description='Description of the AI Application, its purpose, and usage.',
        ),
    ]
    applicationType: ApplicationType
    developmentStage: Optional[DevelopmentStage] = None
    modelConfigurations: Annotated[
        List[ModelConfiguration],
        Field(
            description='Multiple LLM models this application can use for different purposes',
            min_length=1,
        ),
    ]
    primaryModel: Annotated[
        Optional[ability.EntityReference],
        Field(None, description='Primary/default LLM model used by this application'),
    ]
    promptTemplates: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Prompt templates used by this application'),
    ]
    tools: Annotated[
        Optional[ability.EntityReferenceList],
        Field(
            None, description='MCP tools or other tools available to this application'
        ),
    ]
    dataSources: Annotated[
        Optional[ability.EntityReferenceList],
        Field(
            None,
            description='Data sources (tables, APIs, etc.) this application can access',
        ),
    ]
    knowledgeBases: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Vector databases, document stores used for RAG'),
    ]
    upstreamApplications: Annotated[
        Optional[ability.EntityReferenceList],
        Field(
            None,
            description='Other AI applications this application depends on (multi-agent orchestration)',
        ),
    ]
    downstreamApplications: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='AI applications that depend on this application'),
    ]
    framework: Optional[FrameworkInfo] = None
    governanceMetadata: Optional[GovernanceMetadata] = None
    biasMetrics: Optional[BiasMetrics] = None
    performanceMetrics: Optional[PerformanceMetrics] = None
    qualityMetrics: Optional[QualityMetrics] = None
    safetyMetrics: Optional[SafetyMetrics] = None
    testSuites: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Test suites for validating this AI application'),
    ]
    sourceCode: Annotated[
        Optional[str], Field(None, description='Link to source code repository')
    ]
    deploymentUrl: Annotated[
        Optional[str], Field(None, description='Production deployment endpoint')
    ]
    documentation: Annotated[
        Optional[str], Field(None, description='Link to external documentation')
    ]
    owners: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Owners of this AI Application'),
    ]
    followers: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Followers of this AI Application'),
    ]
    domain: Annotated[
        Optional[ability.EntityReference],
        Field(None, description='Domain the AI Application belongs to'),
    ]
    dataProducts: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Data products this AI Application is part of'),
    ]
    tags: Annotated[
        Optional[List[ability.TagLabel]],
        Field(None, description='Tags for this AI Application'),
    ]
    version: Annotated[
        Optional[ability.EntityVersion],
        Field(None, description='Metadata version of the entity'),
    ]
    updatedAt: Annotated[
        Optional[ability.Timestamp],
        Field(None, description='Last update time in Unix epoch milliseconds'),
    ]
    updatedBy: Annotated[
        Optional[str], Field(None, description='User who made the update')
    ]
    href: Annotated[
        Optional[ability.Href], Field(None, description='Link to this resource')
    ]
    changeDescription: Annotated[
        Optional[ability.ChangeDescription],
        Field(None, description='Change that led to this version'),
    ]
    incrementalChangeDescription: Annotated[
        Optional[ability.ChangeDescription],
        Field(None, description='Change that led to this version'),
    ]
    deleted: Annotated[
        Optional[bool],
        Field(
            False, description='When true, indicates the entity has been soft deleted'
        ),
    ]
    certification: Optional[AssetCertification] = None
    extension: Annotated[
        Optional[ability.EntityExtension],
        Field(None, description='Entity extension data with custom attributes'),
    ]
    domains: Annotated[
        Optional[ability.EntityReferenceList],
        Field(None, description='Domains the AI Application belongs to'),
    ]
    votes: Annotated[Optional[Votes], Field(None, description='Votes on the entity')]
    lifeCycle: Annotated[
        Optional[LifeCycle],
        Field(None, description='Life Cycle properties of the entity'),
    ]
    sourceHash: Annotated[
        Optional[str],
        Field(
            None, description='Source hash of the entity', max_length=32, min_length=1
        ),
    ]
